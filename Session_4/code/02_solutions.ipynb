{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama3.2:1B\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Simple Chain with Retrieval\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Implement a simple RAG chain with ChatOllama, HuggingFaceEmbeddings and Chroma.\n",
    "\n",
    "Process:\n",
    "\n",
    "1. Retrieve documents from chroma db based on query\n",
    "2. Invoke chain with retrieved documents as input\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "- load llm model via ollama\n",
    "- load embedding model via ollama with `ollama pull pull bge-m3` (if not yet done)\n",
    "- create chroma db client\n",
    "- create prompt template for summarization\n",
    "- create simple chain with following steps: retrieved documents, prompt, model, output parser\n",
    "- create query and perform similarity search with a query\n",
    "- invoke chain and pass retrieved documents to the chain\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- [RAG with Ollama](https://python.langchain.com/v0.2/docs/tutorials/local_rag/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embedding_model = OllamaEmbeddings(\n",
    "    model=\"bge-m3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "import chromadb\n",
    "import chromadb\n",
    "from chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n",
    "\n",
    "client = chromadb.HttpClient(\n",
    "    host=\"localhost\",\n",
    "    port=8000,\n",
    "    ssl=False,\n",
    "    headers=None,\n",
    "    settings=Settings(allow_reset=True, anonymized_telemetry=False),\n",
    "    tenant=DEFAULT_TENANT,\n",
    "    database=DEFAULT_DATABASE,\n",
    ")\n",
    "\n",
    "collection = client.get_or_create_collection(\"ai_model_book\")\n",
    "\n",
    "vector_db_from_client = Chroma(\n",
    "    client=client,\n",
    "    collection_name=\"ai_model_book\",\n",
    "    embedding_function=embedding_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the main themes in these retrieved docs: {docs}\"\n",
    ")\n",
    "\n",
    "\n",
    "# Convert loaded documents into strings by concatenating their content\n",
    "# and ignoring metadata\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "chain = {\"docs\": format_docs} | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'page': 33, 'source': './AI_Book.pdf'}, page_content='Types of Machine Learning Systems\\nThere are so many different types of Machine Learning systems that it is useful to\\nclassify them in broad categories based on:\\n•Whether or not they are trained with human supervision (supervised, unsuper‐\\nvised, semisupervised, and Reinforcement Learning)\\n•Whether or not they can learn incrementally on the fly (online versus batch\\nlearning)\\n•Whether they work by simply comparing new data points to known data points,\\nor instead detect patterns in the training data and build a predictive model, much\\nlike scientists do (instance-based versus model-based learning)\\nThese criteria are not exclusive; you can combine them in any way you like. For\\nexample, a state-of-the-art spam filter may learn on the fly using a deep neural net‐\\nwork model trained using examples of spam and ham; this makes it an online, model-\\nbased, supervised learning system.\\nLet’s look at each of these criteria a bit more closely.\\nSupervised/Unsupervised Learning\\nMachine Learning systems can be classified according to the amount and type of\\nsupervision they get during training. There are four major categories: supervised\\nlearning, unsupervised learning, semisupervised learning, and Reinforcement Learn‐\\ning.\\nSupervised learning\\nIn supervised learning , the training data you feed to the algorithm includes the desired\\nsolutions, called labels  (Figure 1-5 ).\\nFigure 1-5. A labeled training set for supervised learning (e.g., spam classification)\\n8 | Chapter 1: The Machine Learning Landscape'), Document(metadata={'page': 43, 'source': './AI_Book.pdf'}, page_content='results. To reduce this risk, you need to monitor your system closely and promptly\\nswitch learning off (and possibly revert to a previously working state) if you detect a\\ndrop in performance. Y ou may also want to monitor the input data and react to\\nabnormal data (e.g., using an anomaly detection algorithm).\\nInstance-Based Versus Model-Based Learning\\nOne more way to categorize Machine Learning systems is by how they generalize .\\nMost Machine Learning tasks are about making predictions. This means that given a\\nnumber of training examples, the system needs to be able to generalize to examples it\\nhas never seen before. Having a good performance measure on the training data is\\ngood, but insufficient; the true goal is to perform well on new instances.\\nThere are two main approaches to generalization: instance-based learning and\\nmodel-based learning.\\nInstance-based learning\\nPossibly the most trivial form of learning is simply to learn by heart. If you were to\\ncreate a spam filter this way, it would just flag all emails that are identical to emails\\nthat have already been flagged by users—not the worst solution, but certainly not the\\nbest.\\nInstead of just flagging emails that are identical to known spam emails, your spam\\nfilter could be programmed to also flag emails that are very similar to known spam\\nemails. This requires a measure of similarity  between two emails. A (very basic) simi‐\\nlarity measure between two emails could be to count the number of words they have\\nin common. The system would flag an email as spam if it has many words in com‐\\nmon with a known spam email.\\nThis is called instance-based learning : the system learns the examples by heart, then\\ngeneralizes to new cases by comparing them to the learned examples (or a subset of\\nthem), using a similarity measure. For example, in Figure 1-15  the new instance\\nwould be classified as a triangle because the majority of the most similar instances\\nbelong to that class.\\n18 | Chapter 1: The Machine Learning Landscape'), Document(metadata={'page': 26, 'source': './AI_Book.pdf'}, page_content='PART I\\nThe Fundamentals of\\nMachine Learning'), Document(metadata={'page': 40, 'source': './AI_Book.pdf'}, page_content='Figure 1-12. Reinforcement Learning\\nFor example, many robots implement Reinforcement Learning algorithms to learn\\nhow to walk. DeepMind’s AlphaGo program is also a good example of Reinforcement\\nLearning: it made the headlines in May 2017 when it beat the world champion Ke Jie\\nat the game of Go. It learned its winning policy by analyzing millions of games, and\\nthen playing many games against itself. Note that learning was turned off during the\\ngames against the champion; AlphaGo was just applying the policy it had learned.\\nBatch and Online Learning\\nAnother criterion used to classify Machine Learning systems is whether or not the\\nsystem can learn incrementally from a stream of incoming data.\\nBatch learning\\nIn batch learning , the system is incapable of learning incrementally: it must be trained\\nusing all the available data. This will generally take a lot of time and computing\\nresources, so it is typically done offline. First the system is trained, and then it is\\nlaunched into production and runs without learning anymore; it just applies what it\\nhas learned. This is called offline  learning .\\nIf you want a batch learning system to know about new data (such as a new type of\\nspam), you need to train a new version of the system from scratch on the full dataset\\n(not just the new data, but also the old data), then stop the old system and replace it\\nwith the new one.\\nFortunately, the whole process of training, evaluating, and launching a Machine\\nLearning system can be automated fairly easily (as shown in Figure 1-3 ), so even a\\nTypes of Machine Learning Systems | 15')]\n"
     ]
    }
   ],
   "source": [
    "search_query = \"Types of Machine Learning Systems\"\n",
    "\n",
    "docs = vector_db_from_client.similarity_search(search_query)\n",
    "\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main themes in the retrieved documentation are:\\n\\n1. **Classification of Machine Learning systems**: The documentation discusses how to classify Machine Learning systems based on their characteristics, including whether they are trained with human supervision, can learn incrementally online or offline, and work by comparing new data points to known data points.\\n\\n2. **Types of Supervised Learning**: The documentation explains the four major categories of supervised learning: supervised, unsupervised, semisupervised, and Reinforcement Learning.\\n\\n3. **Instance-Based Versus Model-Based Learning**: It highlights two main approaches to generalization in Machine Learning: instance-based learning, which is trivial but sufficient for simple tasks, and model-based learning, which requires a good performance measure on the training data to generalize effectively.\\n\\n4. **Machine Learning System Design Criteria**: The documentation outlines four criteria used to classify Machine Learning systems:\\n   - Supervised/Unsupervised Learning\\n   - Instance-Based Versus Model-Based Learning\\n   - Batch vs Online Learning\\n   - Whether or not the system can learn incrementally from incoming data\\n\\n5. **Real-World Applications of Machine Learning Systems**: The documentation provides examples of real-world applications, such as spam filters and robots that use Reinforcement Learning algorithms to learn how to walk.\\n\\n6. **Monitoring Performance and Handling Abnormal Data**: It emphasizes the importance of monitoring performance closely and handling abnormal data effectively in Machine Learning systems.\\n\\n7. **Balancing Accuracy with Resource Efficiency**: The documentation highlights the trade-off between accuracy and resource efficiency in Machine Learning system design, where batch learning is generally more efficient but may compromise on accuracy for real-time applications.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Q&A with RAG\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Implement a Q/A retrieval chain with ChatOllama, HuggingFaceEmbeddings and Chroma\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "- create RAG-Q/A prompt template\n",
    "- create retriever from vector db client (instead of manually passing in docs, we automatically retrieve them from our vector store based on the user question)\n",
    "- create simple chain with following steps: retriever, formatting retrieved docs, user question, prompt, model, output parser\n",
    "- create question for Q/A retrieval chain\n",
    "- invoke chain and with question\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- [RAG with Ollama](https://python.langchain.com/v0.2/docs/tutorials/local_rag/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Answer the following question:\n",
    "\n",
    "{question}\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "retriever = vector_db_from_client.as_retriever()\n",
    "\n",
    "qa_rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['Chroma', 'OllamaEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0xffff7b89b510>)\n",
       "           | RunnableLambda(format_docs),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"\\nYou are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\n\\n<context>\\n{context}\\n</context>\\n\\nAnswer the following question:\\n\\n{question}\"))])\n",
       "| ChatOllama(model='llama3.2:1B', _client=<ollama._client.Client object at 0xffff8e7886d0>, _async_client=<ollama._client.AsyncClient object at 0xffffa85c8a90>)\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Supervised learning refers to a type of machine learning where the training data includes labeled solutions or \"targets\" that indicate whether the algorithm should predict certain outcomes, such as spam classification. In this context, the system works perfectly when it receives the correct labels and can make accurate predictions without any human intervention.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is supervised learning?\"\n",
    "\n",
    "qa_rag_chain.invoke(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
